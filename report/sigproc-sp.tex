% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\begin{document}

\title{Summarization: data analysis on italian articles}

% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
       Roberto Zen - 172181\\
       \vspace{1mm}
       \affaddr{University of Trento}\\
       \vspace{1mm}
       \email{roberto.zen@studenti.unitn.it}
% 2nd. author
\alignauthor
       Luca Zamboni - 175606\\
       \vspace{1mm}
       \affaddr{University of Trento}\\
       \vspace{1mm}
       \email{luca.zamboni@studenti.unitn.it}
}


% – Introduction: An introduction to the problem. Why it is interesting? Why would anyone care? Why is your solution good?
% – Motivating Example: An example that shows what you are trying to do.
% - Problem Statement: A problem definition. What problem exactly you try to solve
% – Solution: A description of the solution you provide and its implementation.
% - Related work: A description of other related approaches you have seen in the literature
% - Experimental Evaluation: Multiple experiments that show that your approach works well  comparison  with related work, stress-test to higher data sizes, user evaluation etc.) 

\maketitle
\begin{abstract}
\vspace{2mm}
This is a beautiful abstract.
\end{abstract}

\section{Introduction}
\vspace{2mm}
Every day lots of articles are published by many newspapers and websites. As a consequence, the same news is repeated in many sources causing confusion to readers which have to choose the most interesting ones. Fortunately, there are websites which everyday explore articles from different surces and group them together. The most famous one is Google News\footnote{https://news.google.com}. It actually \textit{aggregates} headlines from news sources worldwide which treat the same news and gives to readers a list of the most \textit{representative} ones for each group. While the title provided by Google is the same as the one written in the source, the body is a paragraph of the article which belongs to the source and allows readers to get instantaneously significant information. The aims of our work is to replicate what Google News provides, focusing on italian articles. The proposed solution provides to readers a list of articles with no duplicates: for each group of similar news we provide the most representative one to show.

\section{Motivating Example}
\vspace{2mm}
The best example from which we took inspiration is Google News. It is simple, fast and personilizable. News may be filtered by personalized interests, locations and other preferences. The aim of our work is to help readers to read news that really represent their interests. In this way, readers do not have to read all the articles that are published during the day and do not have to skip news for which they are not interested in.

%\section{Problem Statement}
%vspace{2mm}
%The problem we face in is twofold: a tipical scenario as the one described in the section 1 can be divided into two steps. The first phase is to find the right way to aggregate similar articles. The second phase is to chose the article from each group which represent the entire cluster. The first challenge we face in was to understand how when different news have to be considered similar.

\section{Data mining}
\vspace{2mm}
\subsection{The Problem}
\vspace{2mm}
We started from a dataset of news collected from different sources. As written in Section 1, our goal is twofold:
\begin{enumerate}
\item We have to find similar news and then we have to cluster them together.
\item We have to find the most rappresentative article for each cluster.
\end{enumerate}
Performance and quality of the results have to be considered together: we need high performance to deal with a huge dataset of articles and at the same time we need quality in order to provide to readers relevent articles with no duplicates.
\subsection{Solution}
\vspace{2mm}
The first step is to remove duplicates. In fact, the same articles might be shared among many sources.\\
The second step is to remove the stop words from the text of the articles. Stop words are usually conjuctions, adjectives, prepositions that are commonly used and repeted over articles. This operation is done because they do not give any additional information about the context of the articles.\\

The two attributes that each news has are title and body. However, we noticed that in many cases considering only the title for the clustering part is more convenient because the title is a collection of few words, tipically keywords, that summarize the entire news.

For the similarity measure between news we need to find the right algorithm which consider two articles similar if they have a lot of common words.

For this part we decided to use the Jaccard similarity because it is largerly used for comparing documents like in our case. This similarity measure is defined as follows:

$$Jaccard(A,B) = \frac{\left\vert A \cap B \right\vert}{\left\vert A \cup B \right\vert}$$

In order to use the Jaccard similarity between news, we built a matrix called \textit{characteristic matrix} \cite{book:MMD}. This matrix is defined as follows: rows are the set of words in the dataset while columns are the articles. Each cell can take value 1 if the element is in the relative document and 0 if not.

A problem of this matrix is that it is really sparse, due to the fact that there are a lot of zeros. To optimize the computation of the Jaccard similarity within this matrix we build a new one, which is significantly smaller. The new matrix is called \textit{signature matrix} and it uses a min hash function. As written in \cite{book:MMD}, if the number of permutation is high (e.g. 100 permutations) this signature matrix preserves the distance beetween documents (in our case articles). The advantage of having this matrix is that the space occupied in memory is proportionated to the number of permutations instead of the number of words.

Once that the matrix is defined, different tecniques were experimented in order to cluster news.

Our first attempt was to cluster news using an agglomerative clustering. The advantage of this method is that is easy to implement and it usually has good performance. 

The algorithm starts with clusters composed by one news each. Afterwards, a recursive strategy is used in order to merge clusters that have the lowest distance between them. The algorithm stops when a threshold value is reached. The distance measure used is:
$$ distance(e_1,e_2) = 1 - jaccard(e_1,e_2)$$
We always merge the two closer cluster. To determine the distance between two clusters we used different tecniques:
\begin{enumerate}
\item The first one is obtained by considering the distance of two news which belong to different clusters and that have the closest distance. The value is actually the closest distance found.
\item The second tecnique is the dual of the first one. So rather than consider the closest distance, the further distance is taken.
\item The third is the average of the distances beetween news of the two clusters.
\end{enumerate}
While we were experimenting these methods we faced two main problems:

The first was that all the three methods gave us always a few number of clusters with a lot of news. This happened also considering the average distances (the third method) we considered the best one. The second problem was the difficulty of determine the threshold value of the algorithms. If it is too high it is likely that few clusters with a lot of news are resulted. On the other hand, if it is too small it is probably that there are a lot of clusters with few news for each.\\

After we faced these two problems we decided to change to another clustering method. The second algorithm we taken in consideration was \textit{K-Means}. We used the column in the characteristic matrix as the vector for a document. With this method we faced three main problems: The first was the same as the one described before and it was about the number of clusters. The second one was due to the fact that K-Means needs an euclidean distance to decide the centroids of the clusters and between articles is not the best measure of comparison. The last problem was that K-Means was really slow for our tasks even with datasets of 500 or 1000 news.

As a consequence, we decided to follow a new approach based on two main steps:
\begin{enumerate}
\item We start by putting all the news in one single cluster and we divide it with the recursive strategy mentioned before.
\item We merge (aggregate) the clusters that are similar each other.
\end{enumerate}
In order to divide the clusters we used the following method. For each cluster, the Jaccard similarity is computed between all the pais of news the belong to the same group. When we find two news that have a similarity value equal to 0 (it means that they have no words in common) we split the cluster in the following way.

We put the two no correlated articles in two new clusters. Afterward, for every other news that belong to the selected cluster, we put it in the cluster with the higher similarity with the mean of all other object of the cluster. In this way is garanted that the algorithm will stop with a certain number of cluster, in this way we solved the problem that we had with the previous algorithm. It is also garanted that the news in a cluster have at least 1 word in common with the other news.\\
At this point we try to reaggregate some clusters. In order to do this we used the following approach. Fo each cluster we computer the N frequent words. After that, we merge cluster that have at least 2 of the n frequent word in common.

Now that we have cluster we need to extract the representative news for each cluster.\\
We decided to choose as representative news the most similar news to the other news to the cluster. To do this we compute the average similarity and we took the the news that have the higher.

Now that we have cluster of news and the representative news to show to the user we decided to delete the cluster with less than M news. This because we want to present to the user the most important news of the day. In thi way we not only present the most important but we delete also clusters that hava a small ammount of news that in general are not important and maybe are a repetition of a bigger cluster that in some we has been devided.

\subsection{Experiments}
\vspace{2mm}
The measures used to validate our approaches were the internal and external average measures of similarity. The first is the average distance among all the clusters between every pair of news in the same cluster. The final internal values is the average of whole the internal values of the clusters. The second instead is the dual of the previous: the average distance is calculated considering pair of news which do not belong to the same clusters.

We expected that the internal distance must be higher than the external one. In addition, the higher is the distance beetween internal and external the better are the clusters.

Four tests were conducted on three datasets of 250, 500 and 1000 news and were performed on a single machine with \textit{Intel core i7 2.6 GH}, 8 GB of RAM.

The first experiment was to test the performance and the quality of the clusters before and after the aggregation phase. 

\begin{table}[!ht]
\centering
\label{table:norea}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
1000           & 0.353    & 0.125    & 240      \\ 
\end{tabular}
\caption{Tests with no aggregation}
\end{table}

\begin{table}[!ht]
\centering
\label{table:sirea}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 24       \\
500            & 0.265    & 0.115    & 70       \\
1000           & 0.351    & 0.132    & 242     
\end{tabular}
\caption{Tests with aggregation}
\end{table}

As can be seen in both the tables \ref{table:norea} and \ref{table:sirea}, the performance and the quality of the aggregation are the same. Hence, we can say that for the dataset we used the aggregation phase does not increase neither the quality of the clusters nor the performance. As conclusion we decided to do not consider the aggregation phase in our process for the rest of our experiments.

% TEST 2 OK

The second test was conducted to get the internal and external results with respect to the building of the characteristic matrix using first the set of words and then the set of shingles. For the second case, shingles were defined as groups of seven characters.

\begin{table}[h]
\centering
\label{table:matrix_words}
\caption{Internal and external measures using words}
\label{my-label}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Internal and external measures using shingles.}
\label{table:matrix_shingles}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.116    & 0.025    & 150      \\
500            & 0.187    & 0.054    & 651      \\
\end{tabular}
\end{table}

Considering a comparision between the tables above, the differences between the internal and the external similarities are the same for both the tecniques. However, the time spent for the whole process which uses the set of words to build the characteristic matrix is definitively lower than the process which uses a matrix built by the set of shingles. As conclusion, we decided to use a characteristic matrix built starting from the set of words.

% TEST 3 OK

The third test we did was to determine the quality of the clusters considering only the title or both the title and the body as information of the news.

\begin{table}[!ht]
\centering
\label{table:title}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
1000           & 0.353    & 0.125    & 240      \\
\end{tabular}
\caption{Performance and quality using only the title.}
\end{table}

\begin{table}[!ht]
\centering
\label{table:body}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.115    & 0.124    & 120      \\
500            & 0.145    & 0.165    & 398      \\
1000           & 0.275    & 0.206    & 1538 
\end{tabular}
\caption{Performance and quality using both the title and the body.}
\end{table}

As can be seen in the tables \ref{table:title} and \ref{table:body}, using only the title as comparision measure gives us better results not only in term of performance but also in terms of quality of clusters. The reason is that titles have fewer words than the body so the words which belong to the first have more likelihood to be keywords. Moreover, while the internal values in table \ref{table:title} are always higher than the ones in table \ref{table:body}, the external values are lower. Hence, we can conclude that usign only the title as information on this dataset we obtained the best performance and quality.

% TEST 4 da fare

The last test we did was 

As expected, using a signature matrix rather than the entire matrix performs better in terms of speed.

Despite the internal and the external ratio remains the same for both the signature and the entire matrix, the values are higher in the fist case. As conclusion, we decided to use only the entire matrix even though the signature matrix can be considered to increase performance with a little loss of quality.

\begin{table}[!h]
\centering
\label{table:matrix}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
1000           & 0.353    & 0.125    & 240      \\
\end{tabular}
\caption{Results using the characteristic Matrix}
\end{table}

\begin{table}[!h]
\centering
\label{table:sigmatrix}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.050    & 22       \\
500            & 0.265    & 0.115    & 46       \\
1000           & 0.350    & 0.131    & 120 
\end{tabular}
\caption{Results using the signature matrix}
\end{table}

Despite the value of the internal and external measures are lower than the expected one, we personally verified the results and clusters are well defined.

\section{Big Data}
\vspace{2mm}

\subsection{The dataset}
\vspace{2mm}
We started by collecting data from the Google News's website. We built a crawler which downloads the feed rss of the whole set of news published by Google in its home page.
% Copertura live..
Each feed rss downloaded by the crawler is parsed and for each news written in it we extract some attributes. The most relevant ones are the following: title, body, name of the source, publication date, url of the Google's feed and url of the source.

A problem we face in this part was that both the titles and the articles provided by Google were extremely short: less than 70 and 250 characters respectively. Therefore, we decided to get the real articles from the major sources such as \textit{Corriere della Sera}, \textit{La Repubblica}, \textit{ANSA.it}, etc. In order to do that, Google News has been used simply as a mean to get the source url from the feed rss. Afterwards, the crawler is run again to get articles published in the new urls obtained, and finally they are parsed in order to retrieve the new values of the title and the body. In case the original articles are no longer available, only the information retrieve from the Google News's homepage are considered.

Once each article is parsed, it is stored in a json file. We decided to store articles in a single file rather than divide them in multiple files. However, due to the json extension we decided to use, this process can be easily converted in a distributed one using the NoSQL Database Management System MongoDb. Hence, each article can be managed as a document and stored in a distributed environment.

\subsection{Text optimization with Spark}
\vspace{2mm}
Once we stored the list of news, we use Spark to parallelize some functions.

% REMOVE STOP WORDS
% l = jsc.parallelize(fromNewsToTuple(list_news))
% l = l.map(lambda n:(n[0],remove_stop_words_from_string(n[1],stop_words),remove_stop_words_from_string(n[2],stop_words))).collect()
% list_news = reassemblyNews(list_news,l)

Firstly, a combination of map-reduce Spark's APIs is used in order to remove stop words from both the title and the body of each article. In fact, the operation of removing words from text is independent from one article to another and it has been implemented as follows: first, the list of news is mapped into a list of tuples of the form \textit{(id, title, body)} so the remove function can be done in parallel by working on single articles. Afterwards, the remove of the stop words is performed. As result a new tuple is provided with no stop words, so the entire list of tuples can be merged into a list of news overriding the old values of title and body with the new ones.

% KEYWORDS

% jsc = SparkContext(appName="LOADNEWS: Get keywords")
% l = jsc.parallelize(formNewsToIdTitleBodyUrl(list_news))
% l = l.map(lambda n:(n[0], get_keywords((n[1],n[2],n[3])))).collect()
% list_news = reassemblyNewsAndSetKeywords(list_news,l)
% jsc.stop()

Secondly, the keywords and entities extraction operation is performed in Spark as follows: given the list of news, a map function is used to split that list, then each news is treated independently so the keywords that belong to the title, the body and the feed url can be extract in parallel. As result of the previous operation, the set of keywords for each article is taken as input by the merge function which stores them in a new attribute.

Thirdly, duplicates are also removed using Spark. In this case, the map function works as follows: news are considered as a tuple \textit{(id,title)} so

The process that tries to find for each cluster a pair of news which have no correlation between them is executed in Spark similarly to the other processes described in this section. Clusters are first converted in RDDs and then parallelized so the map function disagregates them. Finally, the resulting clusters are collect in a single list of clusters.

Find the article which represents a cluster is also computed in parallel using map-reduce in Spark. In fact, the entire list of clusters is distributed so the selection of the most representative element of the group can be done by independently from one cluster to another.

\subsection{Experiments}

We tested the parallelization with spark with 4 machines: 2 computer with: CPU i7 and 8GB of RAM each. We used a network with a low bandwidth.

\begin{table}[!ht]
\centering
\label{serial}
\begin{tabular}{cccc}
Number of news & Time (s) \\
250            & 26       \\
500            & 72       \\
1000           & 240      \\
\end{tabular}
\caption{Serial execution on 1 machine}
\end{table}

\begin{table}[!ht]
\centering
\label{parallel}
\begin{tabular}{cccc}
Number of news & Time (s) \\
250            & 36       \\
500            & 84       \\
1000           & 272      \\
\end{tabular}
\caption{Parallel execution over 2 machines}
\end{table}

From the table representing the serial execution \ref{serial} and the parallel \ref{parallel} we can see that the in the parallel execution the time of computation is increased as opposed to what we thought. This is due to the fact that the parallel computer are only two and the time of computation for a single map is lower that the time used to transfer data from a pc to the other. \\We think that this bad result is due to the fact that the computer were only two and we should test it on a cluster with an higher number of computer (like amazon clusters) and also a network with a larger bandwidth. If we do so we expect to reduce a lot the global time of computation.
%To the best of our knowledge the time spent for the execution might be reduce if the number of computer and the network bandwith is increased.


\section{Conclusions}
Google News is a well known 


\bibliographystyle{abbrv}
\bibliography{sigproc-sp}
\balancecolumns
\end{document}