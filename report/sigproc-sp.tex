% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\usepackage{listings}

\begin{document}

\title{Summarization: data analysis on italian articles}

% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
       Roberto Zen - 172181\\
       \vspace{1mm}
       \affaddr{University of Trento}\\
       \vspace{1mm}
       \email{roberto.zen@studenti.unitn.it}
% 2nd. author
\alignauthor
       Luca Zamboni - 175606\\
       \vspace{1mm}
       \affaddr{University of Trento}\\
       \vspace{1mm}
       \email{luca.zamboni@studenti.unitn.it}
}


% – Introduction: An introduction to the problem. Why it is interesting? Why would anyone care? Why is your solution good?
% – Motivating Example: An example that shows what you are trying to do.
% - Problem Statement: A problem definition. What problem exactly you try to solve
% – Solution: A description of the solution you provide and its implementation.
% - Related work: A description of other related approaches you have seen in the literature
% - Experimental Evaluation: Multiple experiments that show that your approach works well  comparison  with related work, stress-test to higher data sizes, user evaluation etc.) 

\maketitle
\begin{abstract}
\vspace{2mm}
This is a beautiful abstract.
\end{abstract}

\section{Introduction}
\vspace{2mm}
Every day lots of articles are published by many newspapers and websites. As a consequence, the same news is repeated in many sources causing confusion to readers which have to choose the most interesting ones. Fortunately, there are websites which everyday explore articles from different surces and group them together. The most famous one is Google News\footnote{https://news.google.com}. It actually \textit{aggregates} headlines from news sources worldwide which treat the same news and gives to readers a list of the most \textit{representative} ones for each group. While the title provided by Google is the same as the one written in the source, the body is a paragraph of the article which belongs to the source and allows readers to get instantaneously significant information. The aims of our work is to replicate what Google News provides, focusing on italian articles. The proposed solution provides to readers a list of articles with no duplicates: for each group of similar news we provide the most representative one to show.

\section{Motivating Example}
\vspace{2mm}
The best example from which we took inspiration is Google News. It is simple, fast and personilizable. News may be filtered by personalized interests, locations and other preferences. The aim of our work is to help readers to read news that really represent their interests. In this way, readers do not have to read all the articles that are published and do not have to skip news for which they are not interested in.

%\section{Problem Statement}
%vspace{2mm}
%The problem we face in is twofold: a tipical scenario as the one described in the section 1 can be divided into two steps. The first phase is to find the right way to aggregate similar articles. The second phase is to chose the article from each group which represent the entire cluster. The first challenge we face in was to understand how when different news have to be considered similar.

\section{Data mining}
\vspace{2mm}
\subsection{The Problem}
\vspace{2mm}
The problem is to present to the user tha main news happened the day before. We start from a dataset of news collected from different source. Our goals is divided in two main task:
\begin{enumerate}
\item Find similar news in a day and cluster it together.
\item Find a rappresentative news for each cluster to present to the user.
\end{enumerate}
We also try to have a trade of beetween quality and performance. We need high performance also because the idea is replicate google news that has a lot of sources for each country and a lot of users with gigabytes of data.
\subsection{Solution}
The first step is remove eventual news duplication. This is caused because different newspapers copy the text of the news from other newspapers.\\
The second step is to remove the stop word from the dataset. We remove stop word because they are common and repeated for every news so they doesn't give any information about the news.\\
For every news we have a body and a title. We noticed in many cases that using only the title for the clustering part is more convenient because the title is a collection of words, tipically keywords, that summarize the entire news. This increase of quality using only the title, is due also at the fact that our dataset it was taken from internet pages of newspaper, as explained in the big data part, so in some cases are present also words that are not part of the news. Another advantage of using only the title is that the it has fewer word than the body, so the performance are increased. 
For similarity measure of the news we need to have an high value if the two news have a lot of common word over the totality of the word of each news.For this fact we choosed as similarity the jaccard similarity. The jaccard similarity is largerly used for comparing sets and document like our case. The jaccard similarity is defined in the following formula.$$Jaccard(A,B) = \frac{\left\vert A \cap B \right\vert}{\left\vert A \cup B \right\vert}$$
For every test we also tried to substitute words with shingles of different length. The shingles have the advantage that can be more precise but the performace are really worst.
To optimize the jaccard similarity we have builded a matrix where the row are the element present in the all set and the column are the document. The cell can take value 1 if the element is present in the relative document and 0 if not. With this matrix every jaccard similarity computation have a complexity on O(n) and in this way we compare number which cost a lot less of comparing string. \\
With this matrix we can do another stop of optimization. We can build a signature matrix using a min hash function as described in \cite{book:MMD}. If the number of permutation is high (e.g. 100 permutation) this signature matrix preserve the distance beetween document loosing only a few information. The advantage of having this signature matrix is that it occupies in memory a space proportion to (Documents per Number of permutation) instead of having (Document per Number of item). In this way we save a lot space and a lot time in computation.

We tryed different tecniques to try to cluster news.
Our first attempt to cluster news is the agglomerative clustering. This is the very basic idea. The advantage of this method is that is easy to implement and it has a very good performance. The algorithms starts with clusters of one news each. With a recoursive strategy we continuesly merge the 2 cluster with the lowest distance. We stop we the distance of the two closer cluster over a threashold value.\\
The distance measure used is: $$ distance(C_1,C_2) = 1 - jaccard(C_1,C_2)$$
We always merge the two closer cluster. To determine the distance beetween to cluster we used different tecnique. The first one is to choose for each of the two cluster the closest point to the other cluster and take the distance of this two point as the distance of the two cluster. The second tecnique, similarly as the first, is to choose for each of the two cluster the further point to the other cluster and take the distance of this two point as the distance of the two cluster. The third is take the average of the distance beetween the point of the two cluster as the distance of the two clusters.\\
We this clustering method we faced 2 main problems. The first one is that there was always few cluster really big with a lot of news and a lot of small clusters. This happened with all of the three of distance measure beetween clusters, also with takeing the average that we taught it was the best. The second problem is the difficulty of determine the threshold value to stop the clustering. If is too high there are few clusters with a lot of news and if it is to small there are a too much clusters with few news each.\\
After we faced this two problems we decided to abandon this idea and we changed clustering method.

The second algorithm used for the clustering task is K-Means.\\
K-Means is a well known algorithm. We used for the vector of a document the column in the matrix described before. We this clustering we face 3 main problems. The first is like the one before. Decide the number of cluster. The second one is due to the fact that K-Means need an eucliden distance to decide centroids. And an euclidean distance beetween document is not well defined so the clusters also with a small dataset where terrible. The last problem was that K-Means is really slow also if it is parallelized.\\
Also in this case we decided to not follow this way.

Our final approach in order to perform the clustering is made in two principle steps:
\begin{enumerate}
\item Start with a single cluster and divide it with recursive strategy.
\item Reaggregate clusters that are similar.
\end{enumerate}
To divide the cluster we used the following method. For every news in the cluster we compute the jaccard similarity with the other news in the cluster. When we find a news that have similarity 0 (it means that they have no words in common) we split the cluster in the following way. We put the two no correlated in two different clusters. For every other news we put it in the cluster with the higher similarity with the mean of all other object of the cluster. In this way is garanted that the algorithm will stop with a certain number of cluster, in this way we solved the problem that we had with the previous algorithm. It is also garanted that the news in a cluster have at least 1 word in common with the other news.\\
At this point we try to reaggregate some clusters. In order to do this we used the following approach. Fo each cluster we computer the N frequent words. After that, we merge cluster that have at least 2 of the n frequent word in common.

Now that we have cluster we need to extract the representative news for each cluster.\\
We decided to choose as representative news the most similar news to the other news to the cluster. To do this we compute the average similarity and we took the the news that have the higher.

Now that we have cluster of news and the representative news to show to the user we decided to delete the cluster with less than M news. This because we want to present to the user the most important news of the day. In thi way we not only present the most important but we delete also clusters that hava a small ammount of news that in general are not important and maybe are a repetition of a bigger cluster that in some we has been devided.

\subsection{Experiments}
The measures used to validate our approach are the internal and external averege of similarity. The internal is defined as follow. In every cluster we comput the average similarity for every news in the cluster and after we computer the average of this measure. The external instead is defined as the average of similarity for every news with other news of other clusters. Internal must be higher than external and  higher is the distance beetween internal and external better is the clustering.
Test are made on: Processo - Intel core i7 2.6 GH , Ram - 8 GB
The first experiment is to test if wthe part we we try to reggregate is usefull under the prospect of quality and performance.
\begin{table}[!ht]
\centering
\label{table:norea}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
1000           & 0.353    & 0.125    & 240      \\ 
\end{tabular}
\caption{Test without reassembling}
\end{table}

\begin{table}[!ht]
\centering
\label{table:sirea}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 24       \\
500            & 0.265    & 0.115    & 70       \\
1000           & 0.351    & 0.132    & 242     
\end{tabular}
\caption{Test with reassembling}
\end{table}

As we can see in the tables \ref{table:norea} and \ref{table:sirea} the performance and the quality of aggregating are the same in both table. So we can conclude that the rissembler part is not really usefull but sometimes it increase the quality by a bit.
The second experiment experiment that we did is to determine if the quality is higher if we use title and the body of the news as information for the clustering.

\begin{table}[!ht]
\centering
\label{table:title}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
1000           & 0.353    & 0.125    & 240      \\
\end{tabular}
\caption{Performance and quality unsing only the title}
\end{table}

\begin{table}[!ht]
\centering
\label{table:body}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.115    & 0.124    & 120      \\
500            & 0.145    & 0.165    & 398      \\
1000           & 0.275    & 0.206    & 1538 
\end{tabular}
\caption{Performance and quality unsing title and body}
\end{table}

As we can see from the tables \ref{table:title} and \ref{table:body} we can conclude that using only the title of a news is convinient not only in performance of the algorithm, but also in quality of cluster because internal are higher and external lower. We can definitely say that on this dataset usign only the title as information is better.
The third test is to see if there is difference beetween shingles and word in performance and quality result. We choose shingles of 7 characters.
\begin{table}[]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.204    & 0.051    & 26       \\
500            & 0.268    & 0.117    & 72       \\
\end{tabular}
\end{table}

\begin{table}[]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{cccc}
Number of news & Internal & External & Time (s) \\
250            & 0.116    & 0.025    & 150      \\
500            & 0.187    & 0.054    & 651      \\
\end{tabular}
\end{table}

As we can see in table  the difference in time is really high so we choosed to consider only word as information for the news becasue the ratio beetween the Internal and external similarity is the same in both cases.

\section{Big Data}
\vspace{2mm}

\subsection{The dataset}
\vspace{2mm}
We started by collecting data from the Google News's website. We built a crawler which downloads the feed rss of the whole set of news published by Google in its home page.
% Copertura live..
Each feed rss downloaded by the crawler is parsed and for each news written in it we extract some attributes. The most relevant ones are the following: title, body, name of the source, publication date, url of the Google's feed and url of the source.

A problem we face in this part was that both the titles and the articles provided by Google were extremely short: less than 70 and 250 characters respectively. Therefore, we decided to get the real articles from the major sources such as \textit{Corriere della Sera}, \textit{La Repubblica}, \textit{ANSA.it}, etc. In order to do that, Google News has been used simply as a mean to get the source url from the feed rss. Afterwards, the crawler is run again to get articles published in the new urls obtained, and then they are finally parsed to retrieve the new values of title and the body.

% source of articles because the url of the source was already provided in the feed url.


Afterward, the news are stored in a json file.

We decided to store articles in a single file rather than divide them in multiple files. However, due to the json extension we decided to use, this process can be easily converted in a distributed one using the NoSQL Database Management System MongoDb. Hence, each article can be managed as a document and stored in a distributed environment.

\subsection{Text optimization with Spark}
\vspace{2mm}
Once we stored the list of news, we use Spark to parallelize some functions.

% REMOVE STOP WORDS
% l = jsc.parallelize(fromNewsToTuple(list_news))
% l = l.map(lambda n:(n[0],remove_stop_words_from_string(n[1],stop_words),remove_stop_words_from_string(n[2],stop_words))).collect()
% list_news = reassemblyNews(list_news,l)

Firstly, a combination of map-reduce Spark's APIs is used in order to remove stop words from both the title and the body of each article. In fact, the operation of removing words from text is independent from one article to another and it has been implemented as follows: first, the list of news is mapped into a list of tuples of the form \textit{(id, title, body)} so the remove function can be done in parallel by working on single articles. Afterwards, the remove of the stop words is performed. As result a new tuple is provided with no stop words, so the entire list of tuples can be merged into a list of news overriding the old values of title and body with the new ones.

% KEYWORDS

% jsc = SparkContext(appName="LOADNEWS: Get keywords")
% l = jsc.parallelize(formNewsToIdTitleBodyUrl(list_news))
% l = l.map(lambda n:(n[0], get_keywords((n[1],n[2],n[3])))).collect()
% list_news = reassemblyNewsAndSetKeywords(list_news,l)
% jsc.stop()

Secondly, the keywords and entities extraction operation is performed in Spark as follows: given the list of news, a map function is used to split that list, then each news is treated independently so the keywords that belong to the title, the body and the feed url can be extract in parallel. As result of the previous operation, the set of keywords for each article is taken as input by the merge function which stores them in a new attribute.

Thirdly, duplicates are also removed using Spark. In this case, the map function works as follows: news are considered as a tuple \textit{(id,title)} so

The process that tries to find for each cluster a pair of news which have no correlation between them is executed in Spark similarly to the other processes described in this section. Clusters are first converted in RDDs and then parallelized so the map function disagregates clust. Finally, the resulting clusters are collect in a single list of clusters.

Find the article which represents a cluster is also computed in parallel using map-reduce in Spark. In fact, the entire list of clusters is distributed so the selection of the most representative element of the group can be done by independently from one cluster to another.

\section{Conclusions}
This paragraph will end the body of this sample document.


\bibliographystyle{abbrv}
\bibliography{sigproc-sp}
\balancecolumns
\end{document}